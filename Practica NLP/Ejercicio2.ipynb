{"cells":[{"cell_type":"markdown","source":["# 2. Etapa de preprocesado de texto"],"metadata":{"id":"GpSOfe7vFKDd"},"id":"GpSOfe7vFKDd"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMLkWqQe1l85","executionInfo":{"status":"ok","timestamp":1746293216923,"user_tz":-120,"elapsed":1036,"user":{"displayName":"Xenophorm Gadatea","userId":"02239470114378695609"}},"outputId":"ebc21269-2439-4150-994b-507eaa2da043"},"id":"EMLkWqQe1l85","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## üéØ Consideraciones para la funci√≥n de extracci√≥n de features\n","\n","Crear√© una funci√≥n reutilizable basada en lo siguiente:\n","\n","- **Lematizaci√≥n**: √∫til para modelos simples como TF-IDF (reduce ruido), pero puede ser perjudicial en modelos complejos con embeddings porque pierden contexto y no es necesaria.\n","\n","- **Texto en min√∫sculas**: indiferente para an√°lisis de sentimientos, se normaliza por consistencia, ser√≠a interesante por las marcas, pero la pr√°ctica pide un an√°lisis de sentimientos...\n","\n","- **Signos de exclamaci√≥n e interrogaci√≥n**: importantes, se deben conservar ya que aportan tono emocional.\n","\n","- **Stopwords y tokens no alfanum√©ricos**:\n","  - Ya se trat√≥ en el ejercicio 1, pero aqu√≠ se eliminan todos salvo aquellos con valor emocional como `not`, `no`, `never`, `why`, `how` o `what`.\n","  - Tambi√©n se conservan `!` y `?` por su aporte al tono del mensaje.\n","  - El resto de stopwords comunes y s√≠mbolos sin carga emocional se eliminan para reducir ruido.\n","\n","- **Etiquetas gramaticales (POS tags)**:\n","  - Separarlas (`num_nouns`, `num_verbs`, etc.) es √∫til en modelos tradicionales porque detectan patrones espec√≠ficos.\n","  - En modelos complejos (con embeddings), es mejor no separarlas: se reduce el riesgo de overfitting y el modelo ya entiende el contexto sem√°ntico.\n","\n","- **Idioma**: Escojo y me arriesgo a que todo este en ingl√©s, en un futuro y con m√°s tiempo, quiz√°s se podr√≠a inspeccionar m√°s a fondo si por casualidad hay alguna palabra o texto que este en otro idioma\n","\n","- **Rating**: Como la pr√°ctica especificaba el entrenamiento de modelos de clasificaci√≥n binaria (no multiclase) supervisado, pues me decanto por el sistema tradicional de evaluaci√≥n de ex√°menes, todo lo que es m√°s o igual a 5 (aprobado, valoraci√≥n positiva), y lo que es menos (suspenso, valoraci√≥n negativa), si fuese de 0-5 estrellas el dataset, pues a partir de 2,5"],"metadata":{"id":"hDBp2vVpqzhF"},"id":"hDBp2vVpqzhF"},{"cell_type":"code","source":["!pip install -U spacy\n","!python -m spacy download en_core_web_sm"],"metadata":{"id":"5LekrsFB4Y-1","executionInfo":{"status":"ok","timestamp":1746293236838,"user_tz":-120,"elapsed":19912,"user":{"displayName":"Xenophorm Gadatea","userId":"02239470114378695609"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8df2ac6-ba32-4262-8f7d-42c881b46247"},"id":"5LekrsFB4Y-1","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","execution_count":7,"id":"3f394c01","metadata":{"id":"3f394c01","executionInfo":{"status":"ok","timestamp":1746293238017,"user_tz":-120,"elapsed":1172,"user":{"displayName":"Xenophorm Gadatea","userId":"02239470114378695609"}}},"outputs":[],"source":["import spacy\n","import json\n","import pandas as pd\n","\n","# Cargar modelo spaCy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Stopwords importantes para sentimiento\n","important_stopwords = {\"not\", \"no\", \"never\", \"n't\", \"why\", \"how\", \"what\"}\n","# Signos de puntuaci√≥n que aportan tono emocional\n","important_punct = {\"!\", \"?\"}\n","\n","# is_stop = token es un stop_word\n","# is_alpha = token tiene caracteres solo (n√≠ simbolos, ni caracteres especiales, etc)\n","# is_punct = token es una puntuacion\n","def preprocess_text_sentiment(doc):\n","    tokens = []\n","    for token in doc:\n","        if token.is_space:\n","            continue\n","        if token.is_stop and token.text.lower() not in important_stopwords:\n","            continue\n","        if token.is_punct and token.text not in important_punct:\n","            continue\n","        if token.is_alpha or token.text in important_punct:\n","            tokens.append(token.lemma_.lower())\n","    return \" \".join(tokens)\n","\n","# Estas funciones de este bloque de c√≥digo, las pasar√© a un archivo llamado features.py para poder ser importadas\n","# por Ejercicio3.ipynb sin muchas complicaciones\n","def extract_sentiment_features(json_path):\n","    with open(json_path, mode='r', encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    processed = []\n","\n","    for item in data:\n","        text = item[\"review_text\"]\n","        rating = int(item[\"rating\"])\n","        doc = nlp(text)  # tokeniza el texto\n","        cleaned_text = preprocess_text_sentiment(doc)\n","\n","        features = {\n","            # Texto limpio para TF-IDF, embeddings, etc.\n","            \"clean_text\": cleaned_text,\n","\n","            # Caracter√≠sticas ling√º√≠sticas\n","            \"review_length\": len(text),\n","            \"num_tokens\": len(doc),\n","            \"num_sentences\": len(list(doc.sents)),\n","            \"num_nouns\": sum(1 for token in doc if token.pos_ == \"NOUN\"),\n","            \"num_verbs\": sum(1 for token in doc if token.pos_ == \"VERB\"),\n","            \"num_adjectives\": sum(1 for token in doc if token.pos_ == \"ADJ\"),\n","            \"num_adverbs\": sum(1 for token in doc if token.pos_ == \"ADV\"),\n","            \"has_exclamation\": int(\"!\" in text),\n","            \"has_question\": int(\"?\" in text),\n","            \"rating\": 1 if rating >= 5 else 0  # 0-4 Negativo|0 , 5-10 Positivo|1\n","        }\n","\n","        processed.append(features)\n","\n","    return pd.DataFrame(processed)"]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}