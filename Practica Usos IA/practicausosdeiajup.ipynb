{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9f5d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de dependencias (silenciosa)\n",
    "%pip install langchain langchain-openai python-dotenv openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab6b53f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f408a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_cadena(llm, input_variables, template):\n",
    "    prompt = PromptTemplate(input_variables=input_variables, template=template)\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "def convertir_a_diccionario(texto_llm):\n",
    "    \"\"\"\n",
    "    Intenta convertir una cadena de texto generada por el modelo en un diccionario de Python v√°lido.\n",
    "    Si el texto viene en formato Markdown (ej: con etiquetas ```python), las limpia antes de evaluarlo.\n",
    "    \"\"\"\n",
    "    if texto_llm.startswith(\"```\"):\n",
    "        texto_llm = texto_llm.strip(\"`\").strip()\n",
    "        if texto_llm.startswith(\"python\"):\n",
    "            texto_llm = texto_llm[len(\"python\"):].strip()\n",
    "\n",
    "    try:\n",
    "        return ast.literal_eval(texto_llm)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error al interpretar la respuesta como diccionario:\", e)\n",
    "        print(\"üßæ Contenido recibido:\", texto_llm)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13447312",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22925a",
   "metadata": {},
   "source": [
    "# Paso 1: Extraer informaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfdb3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_chain = crear_cadena(llm, [\"email\"], \"\"\"A partir del siguiente correo extrae esta informaci√≥n:\n",
    "- N√∫mero de pedido\n",
    "- Nombre del remitente\n",
    "- Motivo principal de la solicitud\n",
    "\n",
    "Email:\n",
    "\\\"\\\"\\\"{email}\\\"\\\"\\\"\n",
    "\n",
    "Devuelve un diccionario de Python con las claves: pedido, remitente y motivo. \n",
    "No utilices formato Markdown ni encierres el texto entre comillas triples ni uses etiquetas como '```python'.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50c6e6",
   "metadata": {},
   "source": [
    "# Paso 2: Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d7b33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_chain = crear_cadena(llm, [\"motivo\"], \"\"\"Seg√∫n este motivo: \"{motivo}\", indica si se debe ACEPTAR o RECHAZAR la devoluci√≥n.\n",
    "\n",
    "‚úÖ ACEPTAR si:\n",
    "- Defecto de fabricaci√≥n\n",
    "- Error en el suministro\n",
    "- Producto incompleto desde f√°brica\n",
    "\n",
    "‚ùå RECHAZAR si:\n",
    "- Da√±os durante el transporte (si no es responsabilidad de la empresa)\n",
    "- Manipulaci√≥n del cliente\n",
    "- Solicitud fuera de plazo\n",
    "\n",
    "Responde con: \"ACEPTAR\" o \"RECHAZAR\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce59e8",
   "metadata": {},
   "source": [
    "# Paso 3: Redactar respuesta con firma personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f87fd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_chain = crear_cadena(llm, \n",
    "    [\"decision\", \"remitente\", \"pedido\", \"nombre\", \"cargo\", \"empresa\", \"contacto\"], \n",
    "    \"\"\"Redacta una respuesta formal y emp√°tica para el cliente {remitente}, sobre el pedido {pedido}.\n",
    "\n",
    "Si la decisi√≥n es ACEPTAR:\n",
    "- Agrad√©cele por contactar.\n",
    "- Confirma que el reemplazo ser√° procesado.\n",
    "- Explica brevemente que la empresa cubrir√° el fallo seg√∫n la pol√≠tica.\n",
    "\n",
    "Si la decisi√≥n es RECHAZAR:\n",
    "- Lamenta la situaci√≥n.\n",
    "- Explica que no se puede aceptar la devoluci√≥n seg√∫n la pol√≠tica.\n",
    "- Muestra comprensi√≥n y ofrece ayuda adicional si la necesita.\n",
    "\n",
    "Finaliza con esta firma profesional:\n",
    "\n",
    "{nombre}\n",
    "{cargo}\n",
    "{empresa}\n",
    "{contacto}\n",
    "\n",
    "Decisi√≥n: {decision}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c181a",
   "metadata": {},
   "source": [
    "# Ejecutar pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d8a42",
   "metadata": {},
   "source": [
    "# CASO 1: Solicitud que debe ser RECHAZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f8d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimado Darth M√°rquez,\n",
      "\n",
      "Gracias por ponerse en contacto con nosotros respecto a su pedido #D347-STELLA. Lamentamos sinceramente la situaci√≥n que ha experimentado con su producto.\n",
      "\n",
      "Despu√©s de revisar su caso detenidamente, lamentamos informarle que no podemos aceptar la devoluci√≥n del producto, ya que no cumple con los criterios establecidos en nuestra pol√≠tica de devoluciones. Entendemos que esto puede ser decepcionante y queremos asegurarle que valoramos su comprensi√≥n en este asunto.\n",
      "\n",
      "Estamos aqu√≠ para ofrecerle cualquier asistencia adicional que pueda necesitar. No dude en ponerse en contacto con nosotros si tiene alguna otra consulta o si podemos ayudarle de alguna otra manera.\n",
      "\n",
      "Atentamente,\n",
      "\n",
      "Mar√≠a Fern√°ndez  \n",
      "Responsable de Atenci√≥n al Cliente  \n",
      "Componentes Intergal√°cticos Industriales S.A.  \n",
      "contacto@cii.com\n"
     ]
    }
   ],
   "source": [
    "email = \"\"\"Asunto: Solicitud de reemplazo por da√±os en transporte ‚Äì Pedido #D347-STELLA\n",
    "\n",
    "Estimado equipo de Componentes Intergal√°cticos Industriales S.A.,\n",
    "\n",
    "Me pongo en contacto con ustedes como cliente reciente para comunicar una incidencia relacionada con el pedido #D347-STELLA, correspondiente a un lote de condensadores de fluzo modelo FX-88.\n",
    "\n",
    "Lamentablemente, al recibir el env√≠o, observamos que varios de los condensadores presentaban da√±os visibles. Todo indica que la mercanc√≠a sufri√≥ una ca√≠da durante el transporte interestelar.\n",
    "\n",
    "Solicitamos con urgencia el reemplazo inmediato de las unidades defectuosas.\n",
    "\n",
    "Atentamente,\n",
    "Darth M√°rquez\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar paso 1\n",
    "extract_result = extract_chain.invoke(email)\n",
    "info = convertir_a_diccionario(extract_result['text'])\n",
    "\n",
    "pedido = info[\"pedido\"]\n",
    "remitente = info[\"remitente\"]\n",
    "motivo = info[\"motivo\"]\n",
    "\n",
    "# Ejecutar paso 2\n",
    "decision_raw = eval_chain.invoke({\"motivo\": motivo})\n",
    "decision = decision_raw[\"text\"].strip()\n",
    "\n",
    "# Ejecutar paso 3\n",
    "\n",
    "# Datos de firma personalizados\n",
    "firma_info = {\n",
    "    \"nombre\": \"Mar√≠a Fern√°ndez\",\n",
    "    \"cargo\": \"Responsable de Atenci√≥n al Cliente\",\n",
    "    \"empresa\": \"Componentes Intergal√°cticos Industriales S.A.\",\n",
    "    \"contacto\": \"contacto@cii.com\"\n",
    "}\n",
    "\n",
    "response_result = response_chain.invoke({\n",
    "    \"decision\": decision,\n",
    "    \"remitente\": remitente,\n",
    "    \"pedido\": pedido,\n",
    "    **firma_info # Con ** cop√¨as todo lo de firma_info\n",
    "})\n",
    "\n",
    "print(response_result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d188739",
   "metadata": {},
   "source": [
    "# CASO 2: Solicitud que debe ser ACEPTADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ba3cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimada Luc√≠a Robles,\n",
      "\n",
      "Gracias por ponerse en contacto con nosotros y por informarnos sobre el inconveniente con su pedido XZ901-LUCA. Lamentamos mucho cualquier inconveniente que esto haya podido causarle.\n",
      "\n",
      "Nos complace informarle que hemos revisado su caso y el reemplazo de su pedido ser√° procesado de acuerdo con nuestra pol√≠tica de garant√≠a. Nos aseguraremos de que el fallo sea cubierto completamente por nuestra empresa, ya que valoramos su satisfacci√≥n y confianza en nuestros productos.\n",
      "\n",
      "Si tiene alguna pregunta adicional o necesita m√°s asistencia, no dude en ponerse en contacto con nosotros. Estamos aqu√≠ para ayudarle en lo que necesite.\n",
      "\n",
      "Atentamente,\n",
      "\n",
      "Mar√≠a Fern√°ndez  \n",
      "Responsable de Atenci√≥n al Cliente  \n",
      "Componentes Intergal√°cticos Industriales S.A.  \n",
      "contacto@cii.com\n"
     ]
    }
   ],
   "source": [
    "email_aceptar = \"\"\"Asunto: Devoluci√≥n por defecto de fabricaci√≥n ‚Äì Pedido #XZ901-LUCA\n",
    "\n",
    "Estimado equipo de Componentes Intergal√°cticos Industriales S.A.,\n",
    "\n",
    "Les escribo para informarles que el pedido #XZ901-LUCA, compuesto por una serie de microprocesadores CU-92, presenta un defecto de f√°brica: varias unidades no responden a la activaci√≥n b√°sica ni siquiera tras revisi√≥n t√©cnica.\n",
    "\n",
    "Solicito formalmente la devoluci√≥n o el reemplazo de las unidades defectuosas.\n",
    "\n",
    "Gracias por su atenci√≥n.\n",
    "\n",
    "Atentamente,\n",
    "Luc√≠a Robles\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar paso 1\n",
    "extract_result_aceptar = extract_chain.invoke(email_aceptar)\n",
    "info_aceptar = convertir_a_diccionario(extract_result_aceptar['text'])\n",
    "\n",
    "pedido2 = info_aceptar[\"pedido\"]\n",
    "remitente2 = info_aceptar[\"remitente\"]\n",
    "motivo2 = info_aceptar[\"motivo\"]\n",
    "\n",
    "# Ejecutar paso 2\n",
    "decision_raw2 = eval_chain.invoke({\"motivo\": motivo2})\n",
    "decision2 = decision_raw2[\"text\"].strip()\n",
    "\n",
    "# Ejecutar paso 3\n",
    "response_result2 = response_chain.invoke({\n",
    "    \"decision\": decision2,\n",
    "    \"remitente\": remitente2,\n",
    "    \"pedido\": pedido2,\n",
    "    **firma_info\n",
    "})\n",
    "\n",
    "print(response_result2[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
